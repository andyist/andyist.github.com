{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Well Dorset Referral Trend Causal Inference\n",
    "Causal inference analysis for Live Well Dorset programmes communication interventions. \n",
    "[Research project](https://andyist.github.io/mres/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                              # tables and data manipulations\n",
    "from causalimpact import CausalImpact            # estimate causal effect of intervention on a time series\n",
    "from datetime import datetime                    # date helpers\n",
    "import warnings                                  # `do not disturbe` mode              \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run Livewell.ipynb # Project specific helpers\n",
    "\n",
    "#Load and prepare client data (not publicly available)\n",
    "clients = pd.read_csv(\"csv-data/18Jan2019/clients.csv\", index_col='clientID', parse_dates=['DateRegistered','Date_registered_Month_Year'], dayfirst=True)\n",
    "clients = prepare_clients(clients)\n",
    "clients = clients.loc[~clients.DateRegistered.isin(['2016-06-15 17:03:00','2016-06-15 17:04:00'])]\n",
    "clients = clients.loc[clients.DateRegistered >= '2016-01-01 00:00:00']\n",
    "# Remove the time component from the date stamps (we are not interested in finer resolutions than daily)\n",
    "clients = clients.assign(DateRegistered=clients.DateRegistered.dt.round('D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Counting referrals\n",
    "This analysis is conducted using only referral date and if the refereal soure is defined as GP based or not. In preperation the two parameteres are extracted from the general client data, the GP source is then split to two dummy columns represented by boolean vaulues. This structrue allows for daily grouping and counting of the GP and non GP referrrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split gp_referral into boolean columns\n",
    "gp_dates = clients[['DateRegistered','gp_referral']]\n",
    "gp_dates['gp_referral'] = gp_dates['gp_referral'].astype(str)\n",
    "dum = gp_dates.gp_referral.str.get_dummies().astype(bool)\n",
    "gp_dates = pd.concat([gp_dates, dum], axis=1)\n",
    "gp_dates.rename(columns = {'0': 'no-gp', '1': 'gp'}, inplace=True)\n",
    "# Group by date, counting referrals\n",
    "gp_date_counts = gp_dates.groupby('DateRegistered').sum()\n",
    "gp_date_counts = gp_date_counts.reset_index()\n",
    "gp_date_counts['DateRegistered'] = pd.to_datetime(gp_date_counts['DateRegistered'])\n",
    "gp_date_counts = gp_date_counts.set_index('DateRegistered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Padding missing values\n",
    "The inconsistent nature of referral gathering results in the possability for non existant dates within the timeline. A xero fill process is added to pad the data such that missing dates in the time series are accounted for with 0 referrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim date range\n",
    "df = gp_date_counts.copy()\n",
    "# Populate dates with no value as 0 to produce a continuous timeline\n",
    "df = df.asfreq(freq='D', fill_value=0)\n",
    "# Optionally reduce the time series to entries from a specific date\n",
    "#df = df.loc[df.index > '2018-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Causal inferance analysis\n",
    "The analysis is acheived using the Caulsa Impact library developed by Brodersen, K.H. et al (2015). The exmaple used in this study realied upon a discreeet intervention date being identified with a format of year,month,day. This is subsuqnelty used by a project specific get_periods function to standardise the production of boundary dates. This function requires the data frame to be analysed (as results fomr steps 1 and 2), the intervention date object, and the post period with option for a pre-period multiplier - that is how much more pre-period date range should be used for the analysis compared to the desire post period counterfactual projection. \n",
    "\n",
    "The Causal Impact library provides a useul interface for outputting the statistical results summary and visualisations if required. \n",
    "\n",
    "It is intended that this approach be run for each intervention date that exists within the date range and the statistical results be gathered and reviewed as per the researches particular requirments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2017-10-01 to 2018-05-29\n",
      "-------\n",
      "Posterior Inference {Causal Impact}\n",
      "                          Average            Cumulative\n",
      "Actual                    8.0                488.0\n",
      "Prediction (s.d.)         5.7 (0.7)          348.5 (43.9)\n",
      "95% CI                    [4.3, 7.1]         [263.3, 435.3]\n",
      "\n",
      "Absolute effect (s.d.)    2.3 (0.7)          139.5 (43.9)\n",
      "95% CI                    [0.9, 3.7]         [52.7, 224.7]\n",
      "\n",
      "Relative effect (s.d.)    40.0% (12.6%)      40.0% (12.6%)\n",
      "95% CI                    [15.1%, 64.5%]     [15.1%, 64.5%]\n",
      "\n",
      "Posterior tail-area probability p: 0.0\n",
      "Posterior prob. of a causal effect: 100.00%\n",
      "\n",
      "For more details run the command: print(impact.summary('report'))\n"
     ]
    }
   ],
   "source": [
    "# Set the date of the intervention\n",
    "intervention = datetime(2018,3,29)\n",
    "# Prepare pre and post date ranges - default pre is 3 times post which is 28 days\n",
    "pre_period, post_period = get_periods(df, intervention, 60, 3)\n",
    "# Reduce the time series to the period of analysis\n",
    "mask = ((df.index >= pre_period[0]) & (df.index <= post_period[1]))\n",
    "s = df.loc[mask]\n",
    "s = s[['gp','no-gp']]\n",
    "# Run the analysis and output the sumary results\n",
    "ci = CausalImpact(s, pre_period, post_period)\n",
    "print('From ' + pre_period[0] + ' to ' + post_period[1])\n",
    "print('-------')\n",
    "print(ci.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ci.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brodersen, K.H. et al., 2015. Inferring causal impact using Bayesian structural time-series models. Annals of Applied Statistics, 9, pp.247â€“274.\n",
    "https://ai.google/research/pubs/pub41854"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
