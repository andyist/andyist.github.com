{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Well helper functions\n",
    "Functions developed to specifically assist processing of Live Well Dorset wellbeing service data ready for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate categorical values from client (demographic) data set\n",
    "This function extrapolates categorical values for use during stratification and analysis. Results are returned as additional fields in the supplied pandas data frame. \n",
    "* Gender (binary numeric) \n",
    "* Month of year\n",
    "* Age groups (10 year bins)\n",
    "* Binary numeric GP referal source \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_clients(df):\n",
    "    # Numericise the gender field for arithmetic corrlations\n",
    "    df['gender_numeric'] = np.nan\n",
    "    df['gender_numeric'][df.Gender == 'Male'] = 0\n",
    "    df['gender_numeric'][df.Gender == 'Female'] = 1\n",
    "\n",
    "    # Bin dates by month\n",
    "    df['YearMonth'] = df.Date_registered_Month_Year.map(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "    # Bin ages by 10 year divisions\n",
    "    groups = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90+']\n",
    "    df['age_group'] = pd.cut(df.Age, range(0, 101, 10), right=False, labels=groups)\n",
    "\n",
    "    # Mark GP referals by practice staff and those with \"Doctor\" in the referal source identifier that are not hospital related\n",
    "    ref_filter = ['GP','Doctor','Doctor, Community Group','Doctor, Doctors','Practice Nurse','Health Care Assistant, Doctors','Midwife, Doctors','Nurse, Doctors','Practice Nurse, Doctors']\n",
    "    df['gp_referral'] = 0\n",
    "    df['gp_referral'].loc[df['ReferralSource'].isin(ref_filter) | df['how_a'].isin(ref_filter) | df['how_a'].isin(ref_filter) | df['referral_combined'].isin(ref_filter)] = 1\n",
    "    df['gp_referral'].sum()\n",
    "\n",
    "    # Mark GP referals by practice staff and those with \"Doctor\" in the referal source identifier that are not hospital related\n",
    "    ref_filter = ['Doctor','Doctor, Community Group','Doctor, Doctors','Practice Nurse','Health Care Assistant, Doctors','Midwife, Doctors','Nurse, Doctors','Practice Nurse, Doctors']\n",
    "    df['gp_referral'] = 0\n",
    "    df['gp_referral'].loc[df['how_a'].isin(ref_filter) | df['referral_combined'].isin(ref_filter)] = 1\n",
    "\n",
    "    # Dataframe of unkown referal sources\n",
    "    #ref_filter = ['Not asked','Other']\n",
    "    #unkown_refs = df.loc[df['how_a'].isin(ref_filter) & df['referral_combined'].isin(ref_filter)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Output a list if all referral types\n",
    "This function returns a list of the unqiue referral sources found within the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def referral_types(df, fields=['how_a','referral_combined']):\n",
    "    return pd.unique(df[fields].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count the number of unique referal types\n",
    "This function includes the number of records found for each of the unique referral source classificaitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_referal_types(df):\n",
    "    return pd.unique(df[['ReferralSource','how_a','referral_combined']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Smoking quantity standardisation \n",
    "This function compares multiple related columns of varying data types and decides to what level the client is/was a smoker and trasnlates this to a simplified numerical categorisation.\n",
    "* 0 - Non smoker\n",
    "* 1 - Smokes 1 to 9 times a day\n",
    "* 2 - Smokes 10 to 19 times a day\n",
    "* 3 - Smokes 20 or more times a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoking_class(values):\n",
    "    # Define standardise codes for various data values\n",
    "    mapping = { 'a. 1-9': 1, 'a.': 1, 'b. 10-19': 2, 'c. 20+': 3, 'New non smoker': 0, 'Non-Smoker': 0, 'Non smoker': 0, 'Cigarettes': 1, 'e-Cigarettes': 1, 'Roll-ups': 1, 'Smoking (cigarettes, cigars, pipe, roll-ups)': 1, 'E-cigs / vape (E-cigarettes)': 1 }\n",
    "    missing_flag = False\n",
    "    zero_flag = False\n",
    "    coded = False\n",
    "    for value in values:\n",
    "        if value in ['Missing']:\n",
    "            missing_flag = True\n",
    "        if value in ['0',0]:\n",
    "            zero_flag = True\n",
    "        if value in mapping:\n",
    "            coded = mapping[value]\n",
    "            continue\n",
    "        if not coded:\n",
    "            if value.isdigit():\n",
    "                value = pd.to_numeric(value)\n",
    "                if value >= 1 and value <= 9:\n",
    "                    coded = 1\n",
    "                elif value < 19:\n",
    "                    coded = 2\n",
    "                elif value >= 20:\n",
    "                    coded = 3\n",
    "    if not coded or missing_flag and zero_flag:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Stadardise case pathway data\n",
    "This function reviews and consolidates tracking data for the 4 service pathways offered by Live Well Dorset. Through initial analysis is was found that numerous aspects of the data were incomplete or poorly structures (multiple interpretable values). The formalised variables are appended to the original data frame for use in further analysis. Definitions of each pathway 'success' state are detailed in the accompanying thesis document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cases(df):\n",
    "    # Loop all case records\n",
    "    for index, row in df.iterrows():\n",
    "        pathway_count = 0\n",
    "        followup_count = []\n",
    "        pathways_success = np.NaN\n",
    "         # Smoking reduction pathway\n",
    "        if row['Smoking_PathwayActivatedFlag'] == 1:\n",
    "            pathway_count += 1\n",
    "            # Ignore rows who start as non smokers (this should be captured with the above, but better to be sure)\n",
    "            if (row['Smok_Init_Qty_Day_Group'] != '0') & (row['Smoking_InitialQtyPerDay'] != 'Non smoker') & (row['Smoking_InitialQtyPerDay'] != '0'):\n",
    "                smoking_followups = 0\n",
    "                smoking_success = 0\n",
    "                # Standardise the smoking quantities\n",
    "                smoking_df = {}\n",
    "                start_smoking = smoking_class(row[['Smoking_InitialQtyPerDay','Smok_Init_Qty_Day_Group']].values)\n",
    "                smoking_df['Smoker3'] = smoking_class(row[['Smoking_ThreeMthFUpQtyPerDay','Smoking_3_Month_Daily_Quantity']].values)\n",
    "                smoking_df['Smoker6'] = smoking_class(row[['Smoking_SixMthFUpQtyPerDay','Smoking_6_Month_Daily_Quantity']].values)\n",
    "                smoking_df['Smoker12'] = smoking_class(row[['Smoking_TwelveMthFUpQtyPerDay','Smok_12_Months_Qty_Day_group']].values)\n",
    "                # Process each potential followup\n",
    "                for key in smoking_df:\n",
    "                    if not math.isnan(smoking_df[key]):\n",
    "                        smoking_followups += 1\n",
    "                        end_smoking = smoking_df[key]\n",
    "                # Flag if smoking has reduced\n",
    "                net_smoking_reduction = float('nan')\n",
    "                if end_smoking < start_smoking:\n",
    "                    smoking_success = 1\n",
    "                    pathways_success = 1\n",
    "                    smoking_net_reduction = start_smoking - end_smoking\n",
    "                else:\n",
    "                    if smoking_followups > 0:\n",
    "                        smoking_success = 0\n",
    "                    else:\n",
    "                        smoking_success = -1\n",
    "                df.at[index,'smoking_followups'] = smoking_followups\n",
    "                followup_count.append(smoking_followups)\n",
    "                df.at[index,'smoking_success'] = smoking_success\n",
    "\n",
    "        # Weight loss pathway\n",
    "        if row['Weight_PathwayActivatedFlag'] == 1 and row['Weight_Initial'] > 0:\n",
    "            pathway_count += 1\n",
    "            weight_followups = 0\n",
    "            weight_success = 0\n",
    "            end_weight = row['Weight_Initial']\n",
    "            for field in ['Weight_ThreeMthFUpWeight','Weight_SixMthFUpWeight','Weight_TwelveMthFUpWeight']:\n",
    "                # Process each potential followup\n",
    "                if row[field] > 0:\n",
    "                    weight_followups += 1\n",
    "                    end_weight = row[field]\n",
    "            # Flag if weight has been lost\n",
    "            net_weight_loss = float('nan')\n",
    "            if end_weight < row['Weight_Initial']:\n",
    "                weight_net_loss = row['Weight_Initial'] - end_weight\n",
    "                weight_net_loss_percent = (row['Weight_Initial'] - end_weight) * (100/row['Weight_Initial'])\n",
    "                if weight_net_loss_percent > 5: # Success is a 5% loss or more\n",
    "                    weight_success = 1\n",
    "                    pathways_success = 1\n",
    "                else:\n",
    "                    weight_success = 0\n",
    "            else:\n",
    "                if weight_followups > 0:\n",
    "                    weight_success = 0\n",
    "                else:\n",
    "                    weight_success = -1\n",
    "            df.at[index,'weight_followups'] = weight_followups\n",
    "            followup_count.append(weight_followups)\n",
    "            df.at[index,'weight_success'] = weight_success\n",
    "            df.at[index,'net_weight_loss'] = net_weight_loss\n",
    "\n",
    "        # Alcohol reduction pathway\n",
    "        # Ignore rows who start as non drinkers (this should be captured with the above, but better to be sure)\n",
    "        if row['Alcohol_PathwayActivatedFlag'] == 1 and row['Alcohol_InitialAlcoholUnit'] != 0:\n",
    "            pathway_count += 1\n",
    "            alcohol_followups = 0\n",
    "            alcohol_success = 0\n",
    "            end_alcohol = row['Alcohol_InitialAlcoholUnit']\n",
    "            for field in ['Alcohol_ThreeMthFUpAlcoholUnit','Alcohol_SixMthFUpAlcoholUnit','Alcohol_TwelveMthFUpAlcoholUnit']:\n",
    "                # Process each potential followup\n",
    "                if row[field] != -1:\n",
    "                    alcohol_followups += 1\n",
    "                    end_alcohol = row[field]\n",
    "            # Flag is alcohol has reduced\n",
    "            net_alcohol_reduction = float('nan')\n",
    "            if end_alcohol < row['Alcohol_InitialAlcoholUnit']: # This is not units, they have to have droppped a banding to be 'successful'\n",
    "                alcohol_success = 1\n",
    "                pathways_success = 1\n",
    "            else:\n",
    "                pathways_success = 0\n",
    "                # alcohol_net_reduction = row['Alcohol_InitialAlcoholUnit'] - end_alcohol This is a categorised value - not calculable\n",
    "            df.at[index,'alcohol_followups'] = alcohol_followups\n",
    "            followup_count.append(alcohol_followups)\n",
    "            if alcohol_followups > 0:\n",
    "                df.at[index,'alcohol_success'] = alcohol_success\n",
    "            else:\n",
    "                # If there were no followups it is unfair to say the pathway did not succeed\n",
    "                df.at[index,'alcohol_success'] = -1\n",
    "            df.at[index,'net_alcohol_reduction'] = net_alcohol_reduction\n",
    "\n",
    "        # Increased activity pathway\n",
    "        if row['Activity_PathwayActivatedFlag'] == 1 and row['Activity_InitialActivityLevel'] > -1:\n",
    "            pathway_count += 1\n",
    "            activity_followups = 0\n",
    "            activity_success = 0\n",
    "            end_activity = row['Activity_InitialActivityLevel']\n",
    "            for field in ['Activity_ThreeMthFUpActivityLevel','Activity_SixMthFUpActivityLevel','Activity_TwelveMthFUpActivityLevel']:\n",
    "                # Process each potential followup\n",
    "                if row[field] != -1:\n",
    "                    activity_followups += 1\n",
    "                    end_activity = row[field]\n",
    "            # Flag is activity has increased\n",
    "            net_activity_increase = float('nan')\n",
    "            if end_activity > row['Activity_InitialActivityLevel']: # This is not units, they have to have droppped a banding to be 'successful'\n",
    "                activity_success = 1\n",
    "                pathways_success = 1\n",
    "            else:\n",
    "                pathways_success = 0\n",
    "                # alcohol_net_reduction = row['Alcohol_InitialAlcoholUnit'] - end_alcohol This is a categorised value - not calculable\n",
    "            df.at[index,'activity_followups'] = activity_followups\n",
    "            followup_count.append(activity_followups)\n",
    "            if activity_followups > 0:\n",
    "                df.at[index,'activity_success'] = activity_success\n",
    "            else:\n",
    "                # If there were no followups it is unfair to say the pathway did not succeed\n",
    "                df.at[index,'activity_success'] = -1\n",
    "            df.at[index,'net_activity_increate'] = net_activity_increase\n",
    "\n",
    "        df.at[index,'pathways_success'] = pathways_success\n",
    "        df.at[index,'pathway_count'] = pathway_count\n",
    "        if len(followup_count):\n",
    "            df.at[index,'followup_count'] = max(followup_count)\n",
    "        else:\n",
    "            followup_count = 0\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Client-Case join\n",
    "This function joins client records to the related cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_clients(df, clients):\n",
    "    # Merge clients with cases data set\n",
    "    df = pd.merge(df, clients, left_on='clientID', right_index=True)\n",
    "    # Remove duplicate case IDs\n",
    "    df.drop_duplicates(subset=\"CaseID\", keep='first', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Format time periods for Causal Impact analysis\n",
    "With a given daily time series dataframe and a specified intervention date, this function returns a pre and post from/to value pair for use with with the caulsal impact library. Intervals (in days) can be optionally include to override the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periods(df, intervention, post_interval = 28, pre_multiplier = 3):\n",
    "    post_from = min(item for item in df.index if item > intervention)\n",
    "    post_to = intervention + timedelta(days=post_interval)\n",
    "    try:\n",
    "        post_to = min(item for item in df.index if item > post_to)\n",
    "    except ValueError:\n",
    "        # We are past the end of the dataset, use the max and inform intead\n",
    "        post_to = max(df.index)\n",
    "        print('Warning; max series date used for post_to: ' + str(post_to) + '. Post period = ' + str(post_to - post_from))\n",
    "    pre_from = intervention - timedelta(days=(post_interval * pre_multiplier))\n",
    "    pre_from = min(item for item in df.index if item > pre_from)\n",
    "    # Get date immediatly before intervention\n",
    "    loc = df.index.get_loc(intervention)\n",
    "    pre_to = df.index[loc]\n",
    "    return [str(pre_from.date()),str(pre_to.date())], [str(post_from.date()),str(post_to.date())];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Structure data for Facebook Prophet library\n",
    "Manipulate dataframe time series to correct structure and naming for use with Facebook Prophet library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_prophet(df, gpref=None, start=False,end=False):\n",
    "    if gpref is not None:\n",
    "        # Filter by GP referals\n",
    "        if gpref:\n",
    "            df = df[(df.gp_referral == 1)]\n",
    "        else:\n",
    "            df = df[(df.gp_referral != 1)]\n",
    "\n",
    "    # Drop dates before start date\n",
    "    if start:\n",
    "        df = df[(df.DateRegistered >= start)]\n",
    "\n",
    "    # Drop dates after end date\n",
    "    if end:\n",
    "        df = df[(df.DateRegistered <= end)]\n",
    "\n",
    "    # Reduce to single date field\n",
    "    df = df[['DateRegistered']]\n",
    "    # Count daily registrations\n",
    "    df = df.groupby([df[\"DateRegistered\"].dt.year, df[\"DateRegistered\"].dt.month, df[\"DateRegistered\"].dt.day]).count()\n",
    "\n",
    "\n",
    "    # Convert index to datetime data type\n",
    "    a = pd.DataFrame(df.index.values.tolist(), columns=['year','month','day'])\n",
    "    df.index = pd.to_datetime(a)\n",
    "\n",
    "    # Format dataframe for FB Prophet library\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['ds', 'y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Generate table data outside of Jupyter notebook  \n",
    "This function is to assist with outputting tabular data for use in other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_html_table_file(mytable):\n",
    "    data, metadata = get_ipython().display_formatter.format(mytable)\n",
    "    with open('tables/referal-demographic-stratification.html', 'w') as f:\n",
    "        f.write(data['text/html'])  # Assuming the object has an HTML representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
